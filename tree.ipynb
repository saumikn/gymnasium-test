{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766b7803-b252-47da-8afc-5f6783a18118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d00c2c-2468-406c-856e-3a39537a231d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "rng = np.random.default_rng()\n",
    "np.set_printoptions(suppress=True, linewidth=150)\n",
    "from tqdm import tqdm, trange\n",
    "from tqdm.contrib.concurrent import process_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d020d0f5-abe1-4c97-9ffb-3abb14042ee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b1d6d9-9d64-4dee-b971-bd3dfedb6bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, b, axis=-1):\n",
    "    x = x - np.max(x)\n",
    "    return np.exp(b*x) / np.exp(b*x).sum(axis=axis, keepdims=True)\n",
    "\n",
    "def make_model(map_size=5, num_nodes=128, num_dense=4):\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    for gpu in tf.config.list_physical_devices('GPU'):\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=(map_size*map_size+map_size+1))\n",
    "    x = tf.keras.layers.Flatten()(inputs)\n",
    "    \n",
    "    for _ in range(num_dense):\n",
    "        x = tf.keras.layers.Dense(num_nodes, activation='relu')(x)\n",
    "    \n",
    "    # output1 = tf.keras.layers.Dense(5, name='Y0')(x)\n",
    "    # output2 = tf.keras.layers.Dense(5, name='Y1')(x)\n",
    "    # model = tf.keras.models.Model(inputs=inputs, outputs=[output1, output2])\n",
    "    \n",
    "    output1 = tf.keras.layers.Dense(5, name='Y0')(x)\n",
    "    output1 = tf.keras.layers.Softmax()(output1)\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=output1)\n",
    "\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "    model.compile(optimizer=opt, loss=loss_fn, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def softmax(x, b, axis=-1):\n",
    "    x = x - np.max(x)\n",
    "    return np.exp(b*x) / np.exp(b*x).sum(axis=axis, keepdims=True)\n",
    "\n",
    "def make_x():\n",
    "    x = arrs\n",
    "    \n",
    "    rand = np.random.random(arrs.shape)\n",
    "    rand = (rand - 0.5) * 2 / 10\n",
    "    # x = x + rand\n",
    "    \n",
    "    x = rng.permuted(x, axis=-1)\n",
    "    return x\n",
    "\n",
    "def eval_model(model, n = 1, disable=True):\n",
    "    rewards = []\n",
    "    branch_rewards = []\n",
    "    for _ in trange(n, disable=disable):\n",
    "        x = make_x()\n",
    "        x_tree = np.concatenate([np.eye(6).astype(int), np.tile(x.flatten(), (6,1))], axis=1)\n",
    "        y_pred = model(x_tree)\n",
    "        branch_reward = (x_tree[0,6:].reshape(5,5) * y_pred[1:].numpy()).sum(axis=1)\n",
    "        rewards.append(y_pred[0].numpy())\n",
    "        # reward = (y_pred[0] * branch_reward).numpy().sum()\n",
    "        # rewards.append(reward)\n",
    "        branch_rewards.append(branch_reward)\n",
    "    return np.array(rewards), np.array(branch_rewards)\n",
    "\n",
    "def make_data(b, n=1, disable=True):\n",
    "    X, Y = [], []\n",
    "    \n",
    "    \n",
    "    for _ in trange(n, disable=disable):\n",
    "        x = make_x()\n",
    "        r1 = (softmax(x, b) * x)\n",
    "\n",
    "        \n",
    "        x0 = [1,0,0,0,0,0] + list(x.flatten())\n",
    "        y0 = rng.choice(np.arange(5), p=softmax((softmax(x, b) * x).sum(axis=1), b))\n",
    "        \n",
    "        pos = [0,0,0,0,0,0]\n",
    "        pos[y0+1] = 1\n",
    "        x1 = pos + list(x.flatten())\n",
    "        y1 = rng.choice(np.arange(5), p=softmax(x, b)[y0])\n",
    "\n",
    "\n",
    "        X.append(x0)\n",
    "        Y.append(y0)\n",
    "        X.append(x1)\n",
    "        Y.append(y1)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c80b30d6-2466-4fc7-bda8-ad0a77b2c2ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01      ,  0.01584893,  0.02511886,  0.03981072,  0.06309573,  0.1       ,  0.15848932,  0.25118864,  0.39810717,  0.63095734,  1.        ,\n",
       "        1.58489319,  2.51188643,  3.98107171,  6.30957344, 10.        ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 12,  12,  12,  12,  12],\n",
       "       [-20,  13,  13,  13,  13],\n",
       "       [-20, -20,  14,  14,  14],\n",
       "       [-20, -20, -20,  15,  15],\n",
       "       [-20, -20, -20, -20,  16]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ns = [0,5,5,6,7,8,9,10,11,12,13,14,15,16,17]\n",
    "\n",
    "students = np.logspace(-2, 1, 16)\n",
    "display(students)\n",
    "\n",
    "arrs = np.triu(np.tile(np.arange(32, 37),(5,1)).T) - 20\n",
    "display(arrs)\n",
    "display(arrs.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9056fb09-fc3f-4ed8-be09-ec4123e1ec35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ed42634-10c5-4475-b89f-0db4f6a77b21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(student):\n",
    "    verbose = False\n",
    "    if student == students[len(students)//2]:\n",
    "        print(f'student == {student:.3f}')\n",
    "        verbose = True\n",
    "    model = make_model()\n",
    "    Xtrain, Ytrain = make_data(student, 2**20, disable=not verbose)\n",
    "    model.fit(Xtrain, Ytrain, verbose=verbose)\n",
    "    reward = eval_model(model, 10000, disable=not verbose)\n",
    "    model.save(f'models/starting_{student:.3f}.keras')\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff09ac6-6397-4ec4-a545-d006daffa337",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rewards = process_map(train_model, students, disable=True, max_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd16bcd-4f61-4f3c-8bea-cd413d62344e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71093b6a-1f0d-4868-9a85-b493a7f8abea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.2964804212139081\n",
      "0.01 0.33785846288511184\n",
      "0.02 0.4378278642599571\n",
      "0.02 0.647389075434481\n",
      "0.03 0.693736171869005\n",
      "0.03 0.7874579513270769\n",
      "0.04 7.078741750161363\n",
      "0.05 7.795493925425227\n",
      "0.06 9.658377430802128\n",
      "0.08 11.098758554756069\n",
      "0.10 11.640565835966449\n",
      "0.13 12.342592899024144\n",
      "0.16 12.941697855760658\n",
      "0.20 13.488325845577119\n",
      "0.25 13.93474442162644\n",
      "0.32 13.7257961992912\n",
      "0.40 13.984633652485046\n",
      "0.50 14.146800002602752\n",
      "0.63 14.408104944015532\n",
      "0.79 14.844945047422428\n",
      "1.00 14.989739154708671\n"
     ]
    }
   ],
   "source": [
    "for r, s in zip(rewards, students):\n",
    "    \n",
    "    res = r[0]*r[1]\n",
    "    res = res.sum(axis=1).mean()\n",
    "    \n",
    "    print(f\"{s:.2f} {res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d99b247-8ffc-40a3-a97c-caa0711de854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef6af282-f6da-44a7-b19f-7f1bc4e586c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010, 2.536, [ 12.           7.97248005   3.05845208  -2.98519532 -10.5030866 ]\n",
      "0.013, 3.140, [12.          8.32589919  3.70121042 -2.19239231 -9.83719922]\n",
      "0.016, 3.866, [12.          8.74106985  4.4790896  -1.19650299 -8.95987224]\n",
      "0.020, 4.725, [12.          9.2186661   5.40557111  0.04450878 -7.79798594]\n",
      "0.025, 5.718, [12.          9.75305389  6.48399883  1.56902907 -6.25605078]\n",
      "0.032, 6.834, [12.         10.3294776   7.6987513   3.39690653 -4.21951701]\n",
      "0.040, 8.044, [12.         10.92197276  9.00499434  5.50362179 -1.57805424]\n",
      "0.050, 9.305, [12.         11.49381646 10.32199117  7.78703938  1.70798935]\n",
      "0.063, 10.564, [12.         12.00263198 11.53914376 10.04749419  5.48399391]\n",
      "0.079, 11.760, [12.         12.41085569 12.54299769 12.02067143  9.28803482]\n",
      "0.100, 12.808, [12.         12.69849399 13.26000329 13.48333628 12.45304773]\n",
      "0.126, 13.599, [12.         12.87102756 13.68920879 14.37096085 14.51479765]\n",
      "0.158, 14.082, [12.         12.95589895 13.89676861 14.79651112 15.52717187]\n",
      "0.200, 14.333, [12.         12.98860406 13.97436382 14.95139334 15.89097348]\n",
      "0.251, 14.479, [12.         12.99792766 13.9955713  14.9920216  15.98298144]\n",
      "0.316, 14.605, [12.         12.99975769 13.99951476 14.9991808  15.99836225]\n",
      "0.398, 14.746, [12.         12.99998375 13.99997001 14.99995335 15.99991408]\n",
      "0.501, 14.907, [12.         12.99999946 13.9999991  14.99999874 15.9999979 ]\n",
      "0.631, 15.086, [12.         12.99999999 13.99999999 14.99999999 15.99999998]\n",
      "0.794, 15.272, [12. 13. 14. 15. 16.]\n",
      "1.000, 15.452, [12. 13. 14. 15. 16.]\n",
      "CPU times: user 10.4 s, sys: 0 ns, total: 10.4 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for b in students:\n",
    "    r1s = []\n",
    "    r2s = []\n",
    "    for _ in trange(10000, disable=True):\n",
    "        x = make_x()\n",
    "        r1 = (softmax(x, b) * x).sum(axis=1)\n",
    "        r2 = (softmax(r1, b) * r1).sum()\n",
    "        \n",
    "        r1s.append(r1)\n",
    "        r2s.append(r2)\n",
    "        \n",
    "    r1s = np.array(r1s)\n",
    "    r2s = np.array(r2s)\n",
    "    print(f\"{b:.3f}, {r2s.mean():.3f}, {r1s.mean(axis=0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688cd270-bad9-4bd0-9933-808737ee4f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b9e197-f4be-428c-9f4d-da3c1bf4117b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "269f7bff-7ea5-4da5-a8dc-f3a9cf16a51d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_training(student, teacher, verbose=False):\n",
    "    import tensorflow as tf\n",
    "    for gpu in tf.config.list_physical_devices('GPU'):\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    \n",
    "    if student == -1:\n",
    "        model2 = make_model()\n",
    "    else:\n",
    "        model2 = tf.keras.models.load_model(f\"models/starting_{student:.3f}.keras\")\n",
    "    # print(f\"{b:.2f}\", end=':    ')\n",
    "    nsum = 0\n",
    "    \n",
    "    X, Y = currs[f\"{teacher:.3f}\"]\n",
    "    perm = np.random.permutation(len(X))\n",
    "    X, Y = X[perm], Y[perm]\n",
    "    \n",
    "    rewards = []\n",
    "    for i in ns:\n",
    "        if i != 0:\n",
    "            n = 2**i\n",
    "            # X, Y = make_data(teacher, n, disable=True)\n",
    "                        \n",
    "            model2.fit(X[nsum:nsum+n], Y[nsum:nsum+n], verbose=False)\n",
    "            nsum += n\n",
    "            \n",
    "        r0, r1 = eval_model(model2, 50)\n",
    "        reward = (r0*r1).sum(axis=1).mean()\n",
    "        rewards.append(reward)\n",
    "        # print(f\"{nsum}    \", end='\\r')\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a324090-5ab1-4dc9-86e7-1b1753ae8b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9a6548c-85ef-4e7b-8f30-ef4e94a0f13a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def exp(student, verbose=True, n=20):\n",
    "    # teachers = np.arange(student, 0.40001, 0.02)\n",
    "    \n",
    "    teachers = students\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Original Student: {student:.3f}')\n",
    "        print()\n",
    "        print('         Curriculum Size')\n",
    "        print('Teacher', end='')\n",
    "        nsum = 0\n",
    "        for i in ns:\n",
    "            if i: nsum += 2**i\n",
    "            print(f\"{nsum:>8}\", end='')\n",
    "        print()\n",
    "\n",
    "\n",
    "    all_res = []\n",
    "    for teacher in teachers:\n",
    "        # print(f\"teacher = {teacher:.2f} \", end='\\r')\n",
    "        res = process_map(eval_training, [student]*n, [teacher]*n, max_workers=10, disable=True)\n",
    "        res = np.array(res).mean(axis=0)\n",
    "        all_res.append(res)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  {teacher:.3f}\", end='  ')\n",
    "            for reward in res:\n",
    "                print(f\"{reward: 6.2f}\", end='  ')\n",
    "            print()\n",
    "\n",
    "    all_res = np.array(all_res)\n",
    "\n",
    "    return all_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0826ac4-e736-40ab-bcec-de7261dd7178",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e17379e9-7e00-4eb1-b0dd-5c780bc48560",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048576"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntotal = (2**np.array(ns[1:])).sum()\n",
    "ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6be9cdd-8604-4a87-b3ff-10b033576e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7864021ad9554721ab77bff6b5aa788a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ntotal = (2**np.array(ns[1:])).sum()\n",
    "\n",
    "currs = process_map(make_data, students, [ntotal]*len(students), max_workers=4)\n",
    "currs = dict(zip([f\"{s:.3f}\" for s in students], currs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b088c774-464d-4248-a318-cca6c5ef217a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Student: -1.000\n",
      "\n",
      "         Curriculum Size\n",
      "Teacher       0      32      64     128     256     512    1024    2048    4096    8192   16384   32768   65536  131072  262144  524288 1048576\n",
      "  0.010   -0.35   -0.49    0.20    0.68    0.52    0.65    0.40    0.70    0.35    0.52    0.43    0.34    0.36    0.35    0.37    0.35    0.36  \n",
      "  0.013    0.69   -0.40   -0.22    0.39    1.48    0.40    0.89    0.87    0.58    0.64    0.47    0.46    0.45    0.42    0.43    0.43    0.43  \n",
      "  0.016   -0.56    0.35    0.63    0.52    1.06    0.42    0.50    0.86    0.58    0.75    0.65    0.56    0.52    0.49    0.52    0.50    0.51  \n",
      "  0.020    0.65   -0.30   -0.02    1.04    1.63    0.54    0.95    1.08    0.75    0.94    0.73    0.65    0.60    0.63    0.61    0.61    0.67  \n",
      "  0.025    0.19    0.58    1.32    0.89    0.20    0.77    1.06    0.66    1.02    0.97    0.83    0.77    0.75    0.76    0.72    0.76    1.14  \n",
      "  0.032   -0.62    1.44    1.83    0.27    1.01    0.77    1.39    0.87    1.16    1.05    0.94    0.90    0.89    0.82    0.80    1.05    1.88  \n",
      "  0.040   -0.13    0.85    1.24    0.94    1.00    0.87    1.41    0.93    1.17    1.16    1.03    1.00    0.87    0.99    1.01    1.80    4.28  \n",
      "  0.050   -0.21    1.20    1.35    0.62    0.46    1.07    1.31    1.05    1.18    1.04    1.02    0.92    1.00    1.08    1.19    3.21    7.19  \n",
      "  0.063    1.46    0.66    0.16    0.30    1.27    1.56    1.17    0.99    1.08    0.82    0.97    0.83    1.03    1.14    1.38    6.35    8.65  \n",
      "  0.079    1.06   -0.12    0.28    0.60    0.51    1.50    0.98    1.10    1.02    0.84    0.77    0.80    0.96    1.11    4.90    7.96    9.70  \n",
      "  0.100   -0.40   -0.45    0.00    0.53    0.36    0.63    0.34    0.62    0.66    0.61    0.63    0.65    0.80    1.46    7.51    9.11   10.54  \n",
      "  0.126    0.30   -1.27   -1.23   -0.30    0.03    0.53    0.58    0.45    0.63    0.44    0.35    0.43    0.69    5.31    9.19   10.11   11.43  \n",
      "  0.158   -0.33   -0.10   -0.27   -0.69   -0.02    0.29    0.31    0.40    0.27    0.19    0.25    0.30    0.65    6.31    9.90   10.84   12.22  \n",
      "  0.200   -1.37   -1.02   -0.75   -0.02   -0.30   -0.13    0.01   -0.07    0.19    0.18    0.12    0.09    0.75    7.10   10.47   11.45   12.72  \n",
      "  0.251    0.69   -0.66   -2.05   -1.65   -0.41   -0.37    0.07   -0.26   -0.06   -0.15   -0.04    0.03    1.56    7.92   10.76   11.90   13.07  \n",
      "  0.316   -1.31   -1.13   -1.90   -1.93   -1.41    0.02   -0.12   -0.28   -0.39   -0.22   -0.27   -0.18    3.38    8.97   11.14   12.20   13.39  \n",
      "  0.398    0.94   -1.63   -2.45   -2.81   -1.82    0.10   -0.07   -0.40   -0.45   -0.44   -0.37   -0.09    5.92    9.69   11.58   12.32   13.60  \n",
      "  0.501   -0.60   -1.21   -2.43   -3.35   -1.34   -0.52   -0.69   -0.87   -0.65   -0.48   -0.64   -0.19    7.11   10.49   11.93   12.63   13.88  \n",
      "  0.631   -0.34   -2.23   -3.11   -3.94   -1.72   -0.86   -0.91   -0.75   -0.75   -0.77   -0.74   -0.30    8.14   11.36   12.56   13.17   14.27  \n",
      "  0.794    0.55   -2.43   -4.24   -5.22   -3.13   -1.02   -0.98   -1.01   -1.01   -0.86   -0.70    1.54    9.47   12.09   13.18   13.65   14.53  \n",
      "  1.000    0.82   -3.11   -5.57   -5.17   -2.65   -0.19   -1.26   -1.18   -0.84   -0.39   -0.59    5.15   10.65   12.85   13.85   14.13   14.65  \n",
      "  1.259   -0.56   -4.02   -6.09   -5.34   -2.22   -0.74   -0.37   -0.91   -0.77   -0.14   -0.31    8.15   12.05   13.43   14.46   14.67   14.88  \n",
      "  1.585   -0.31   -3.95   -5.97   -6.04   -3.37   -0.47   -0.48   -0.61   -0.24    0.41    0.47   10.34   12.95   14.16   14.85   15.13   15.16  \n",
      "  1.995    0.55   -3.75   -6.90   -6.85   -2.39   -1.00   -0.27    0.18    0.23    0.88    2.15   11.67   13.84   14.67   15.11   15.33   15.45  \n",
      "  2.512   -0.07   -4.48   -6.99   -7.88   -2.57   -0.88    0.87    0.16    0.86    1.23    4.66   12.84   14.36   15.09   15.53   15.50   15.73  \n",
      "  3.162    0.21   -3.63   -6.12   -7.52   -3.14   -0.72    1.14    0.75    1.70    2.08    7.43   14.08   14.91   15.31   15.62   15.78   15.77  \n",
      "  3.981   -0.19   -5.00   -7.05   -7.36   -2.45   -0.56    1.43    0.88    1.53    2.40   10.08   14.93   15.24   15.46   15.68   15.87   15.92  \n",
      "  5.012   -0.06   -3.81   -6.82   -7.47   -2.71   -0.53    1.28    0.92    1.71    2.91   12.32   15.43   15.65   15.72   15.78   15.80   15.91  \n",
      "  6.310   -0.17   -5.17   -7.41   -7.37   -2.33   -1.45    0.48    0.77    2.05    2.66   13.28   15.75   15.85   15.78   15.88   15.92   15.94  \n",
      "  7.943    1.30   -4.09   -7.33   -8.29   -2.42   -1.34    0.24    0.81    1.87    2.66   12.91   15.69   15.85   15.84   15.93   15.95   15.98  \n",
      "  10.000    0.10   -4.08   -6.99   -7.72   -2.59   -0.72    0.29    0.78    1.89    2.72   12.85   15.92   15.77   15.85   15.94   15.81   16.00  \n",
      "CPU times: user 2.06 s, sys: 59.1 s, total: 1min 1s\n",
      "Wall time: 8h 10min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res_fresh = exp(-1, n=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724fecd2-ee1a-4a76-84d0-d0c57492e4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ddb0c0-de4a-4812-a53a-38b1597e76e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Student: 0.010\n",
      "\n",
      "         Curriculum Size\n",
      "Teacher       0      32      64     128     256     512    1024    2048    4096    8192   16384   32768   65536  131072  262144  524288 1048576\n",
      "  0.010    0.30    0.31    0.29    0.29    0.28    0.28    0.29    0.30    0.30    0.31    0.35    0.39    0.42    0.31    0.38    0.35    0.34  \n",
      "  0.013    0.30    0.31    0.29    0.29    0.28    0.28    0.30    0.31    0.32    0.35    0.41    0.46    0.48    0.41    0.45    0.45    0.44  \n",
      "  0.016    0.30    0.31    0.29    0.29    0.28    0.28    0.30    0.32    0.34    0.39    0.47    0.53    0.56    0.48    0.52    0.53    0.50  \n",
      "  0.020    0.30    0.31    0.29    0.29    0.28    0.29    0.31    0.34    0.37    0.43    0.54    0.60    0.65    0.57    0.61    0.62    0.58  \n",
      "  0.025    0.30    0.31    0.29    0.30    0.28    0.29    0.33    0.35    0.42    0.47    0.57    0.57    0.66    0.67    0.63    0.71    0.64  \n",
      "  0.032    0.30    0.31    0.29    0.30    0.28    0.29    0.33    0.35    0.44    0.49    0.62    0.62    0.73    0.70    0.71    0.79    0.71  \n",
      "  0.040    0.30    0.31    0.29    0.30    0.29    0.30    0.33    0.36    0.44    0.50    0.64    0.64    0.74    0.73    0.73    0.80    0.75  \n",
      "  0.050    0.30    0.31    0.29    0.30    0.29    0.30    0.33    0.35    0.43    0.49    0.62    0.59    0.66    0.69    0.66    0.73    0.69  \n",
      "  0.063    0.30    0.31    0.29    0.29    0.28    0.27    0.30    0.31    0.37    0.40    0.46    0.47    0.52    0.55    0.54    0.60    0.57  \n",
      "  0.079    0.30    0.31    0.29    0.29    0.27    0.27    0.28    0.27    0.30    0.27    0.27    0.23    0.24    0.29    0.25    0.31    0.24  \n",
      "  0.100    0.30    0.31    0.29    0.29    0.27    0.26    0.25    0.21    0.19    0.08   -0.03   -0.09   -0.11   -0.07   -0.08   -0.09   -0.10  \n",
      "  0.126    0.30    0.31    0.29    0.29    0.27    0.25    0.23    0.15    0.08   -0.11   -0.32   -0.41   -0.52   -0.47   -0.47   -0.49   -0.48  \n",
      "  0.158    0.30    0.31    0.29    0.29    0.27    0.26    0.24    0.13   -0.06   -0.32   -0.54   -0.76   -0.84   -0.88   -0.88   -0.92   -0.88  \n",
      "  0.200    0.30    0.31    0.29    0.29    0.27    0.25    0.21    0.08   -0.15   -0.48   -0.78   -1.04   -1.16   -1.18   -1.17   -1.26   -1.18  \n",
      "  0.251    0.30    0.31    0.29    0.29    0.27    0.24    0.19    0.04   -0.23   -0.62   -1.01   -1.31   -1.50   -1.52   -1.46   -1.60   -1.49  \n",
      "  0.316    0.30    0.31    0.29    0.29    0.27    0.23    0.16   -0.02   -0.35   -0.82   -1.30   -1.64   -1.84   -1.88   -1.84   -2.02   -1.86  \n",
      "  0.398    0.30    0.31    0.29    0.29    0.26    0.21    0.13   -0.05   -0.39   -0.97   -1.61   -1.90   -2.35   -2.28   -2.26   -2.45   -2.30  \n",
      "  0.501    0.30    0.31    0.29    0.29    0.25    0.20    0.10   -0.12   -0.53   -1.20   -1.96   -2.32   -2.83   -2.82   -2.72   -2.99   -2.79  \n",
      "  0.631    0.30    0.31    0.29    0.28    0.25    0.19    0.06   -0.20   -0.69   -1.46   -2.38   -2.77   -3.36   -3.42   -3.24   -3.60   -3.35  \n",
      "  0.794    0.30    0.31    0.29    0.28    0.24    0.18    0.02   -0.28   -0.85   -1.73   -2.80   -3.25   -3.95   -4.06   -3.79   -4.27   -3.92  \n",
      "  1.000    0.30    0.31    0.29    0.28    0.24    0.16   -0.01   -0.36   -1.05   -1.97   -3.21   -3.72   -4.51   -4.57   -4.32   -4.89   -4.53  \n",
      "  1.259    0.30    0.31    0.29    0.28    0.23    0.15   -0.03   -0.42   -1.15   -2.15   -3.53   -4.12   -4.98   -5.14   -4.79   -5.45   -5.06  \n",
      "  1.585    0.30    0.31    0.29    0.28    0.23    0.14   -0.05   -0.45   -1.22   -2.27   -3.81   -4.45   -5.40   -5.61   -5.15   -5.88   -5.50  \n",
      "  1.995    0.30    0.31    0.29    0.28    0.23    0.14   -0.06   -0.47   -1.25   -2.36   -4.04   -4.70   -5.68   -5.98   -5.44   -6.24   -5.86  \n",
      "  2.512    0.30    0.31    0.29    0.28    0.23    0.14   -0.07   -0.48   -1.25   -2.42   -4.21   -4.82   -5.92   -6.26   -5.62   -6.45   -6.10  \n",
      "  3.162    0.30    0.31    0.29    0.28    0.23    0.14   -0.07   -0.48   -1.26   -2.45   -4.33   -4.95   -6.06   -6.42   -5.75   -6.62   -6.29  \n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res020 = exp(0.010, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1192026-5c57-4a0b-95a6-09d054c6d71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0a016c-436b-425f-9052-ff5e0bcac74d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "res010 = exp(0.020, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d0447d-e96e-45cd-8bac-8142962213f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add80dc2-7dd2-4fb0-9134-778750d920c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "res040 = exp(0.040, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cd5287-ccf7-4127-b5c7-686ef886f2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671dc08e-5dcb-4bb6-8798-d0342856f5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20016ccb-d5b8-419f-9bed-be32c1782513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeea951-d9a9-4c9a-97d2-04f8af9d3a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b99f7b-1c40-41e9-afbd-875a21eb75a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41041fb3-9602-4b4c-9cf1-90e00bb007fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a7e20-f634-42a9-8382-1bf3d7c7512a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0aacf37-95a0-46ef-8e79-5045684716ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Student: 0.020\n",
      "\n",
      "         Curriculum Size\n",
      "Teacher       0      32      64     128     256     512    1024    2048    4096    8192   16384   32768   65536  131072  262144\n",
      "  0.010    0.65    0.65    0.61    0.65    0.69    0.67    0.64    0.62    0.58    0.44    0.39    0.35    0.38    0.27    0.36  \n",
      "  0.013    0.65    0.65    0.61    0.65    0.69    0.67    0.65    0.63    0.59    0.47    0.44    0.43    0.46    0.35    0.44  \n",
      "  0.016    0.65    0.65    0.61    0.65    0.69    0.67    0.65    0.63    0.58    0.41    0.43    0.45    0.50    0.46    0.50  \n",
      "  0.020    0.65    0.65    0.61    0.65    0.69    0.67    0.66    0.65    0.61    0.45    0.49    0.53    0.56    0.55    0.59  \n",
      "  0.025    0.65    0.65    0.61    0.65    0.69    0.68    0.67    0.71    0.72    0.62    0.67    0.68    0.65    0.62    0.68  \n",
      "  0.032    0.65    0.65    0.61    0.65    0.69    0.68    0.68    0.72    0.74    0.65    0.71    0.76    0.70    0.69    0.74  \n",
      "  0.040    0.65    0.65    0.61    0.65    0.69    0.68    0.70    0.72    0.76    0.63    0.55    0.72    0.73    0.72    0.76  \n",
      "  0.050    0.65    0.65    0.61    0.65    0.69    0.68    0.69    0.71    0.74    0.60    0.51    0.67    0.66    0.66    0.70  \n",
      "  0.063    0.65    0.65    0.62    0.66    0.69    0.68    0.67    0.66    0.66    0.61    0.48    0.55    0.55    0.43    0.52  \n",
      "  0.079    0.65    0.65    0.62    0.65    0.69    0.67    0.66    0.62    0.60    0.48    0.30    0.30    0.28    0.19    0.25  \n",
      "  0.100    0.65    0.65    0.61    0.65    0.69    0.66    0.64    0.62    0.56    0.33    0.11   -0.05   -0.05   -0.08   -0.09  \n",
      "  0.126    0.65    0.65    0.61    0.65    0.68    0.65    0.61    0.55    0.44    0.13   -0.16   -0.40   -0.44   -0.44   -0.50  \n",
      "  0.158    0.65    0.65    0.61    0.65    0.68    0.63    0.55    0.42    0.17   -0.10   -0.33   -0.82   -0.80   -0.81   -0.85  \n",
      "  0.200    0.65    0.65    0.61    0.65    0.68    0.62    0.52    0.36    0.07   -0.27   -0.56   -1.13   -1.15   -1.13   -1.18  \n",
      "  0.251    0.65    0.65    0.61    0.65    0.67    0.61    0.53    0.39    0.08   -0.44   -0.96   -1.32   -1.46   -1.44   -1.54  \n",
      "  0.316    0.65    0.65    0.61    0.64    0.67    0.60    0.51    0.34   -0.04   -0.61   -1.25   -1.69   -1.81   -1.77   -1.87  \n",
      "  0.398    0.65    0.65    0.61    0.65    0.67    0.59    0.47    0.25   -0.23   -0.78   -1.47   -2.21   -2.27   -2.07   -2.38  \n",
      "  0.501    0.65    0.65    0.61    0.64    0.66    0.58    0.43    0.17   -0.37   -1.02   -1.85   -2.71   -2.79   -2.51   -2.87  \n",
      "  0.631    0.65    0.65    0.61    0.64    0.65    0.57    0.41    0.11   -0.51   -1.27   -2.20   -3.09   -3.37   -2.98   -3.46  \n",
      "  0.794    0.65    0.65    0.61    0.64    0.65    0.56    0.38    0.04   -0.65   -1.48   -2.59   -3.69   -4.02   -3.44   -4.09  \n",
      "  1.000    0.65    0.65    0.61    0.64    0.65    0.55    0.35   -0.02   -0.79   -1.64   -2.91   -4.20   -4.69   -3.94   -4.73  \n",
      "CPU times: user 803 ms, sys: 8.61 s, total: 9.41 s\n",
      "Wall time: 31min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res020 = exp(0.020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec91a9f7-8d1e-4ca3-9ed1-540b2ff2ada0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebf80d08-0e09-410d-a147-177f6724e2fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Student: -1.000\n",
      "\n",
      "         Curriculum Size\n",
      "Teacher       0      32      64     128     256     512    1024    2048    4096    8192   16384   32768   65536  131072  262144\n",
      "  0.010    1.88    0.66    0.41    0.45    0.85    1.04   -0.04   -0.02    0.43    0.43    0.42    0.38    0.41    0.26    0.34  \n",
      "  0.013    0.60    1.12    1.19    0.86    0.41    1.27   -0.20    0.10    0.54    0.66    0.35    0.60    0.47    0.37    0.43  \n",
      "  0.016    0.32   -1.52   -0.68    1.11    1.93    0.96    0.87    0.64    0.36    0.30    0.69    0.48    0.53    0.50    0.50  \n",
      "  0.020   -0.00    0.64    0.66    0.79    2.07    1.34    0.82    0.59    0.10    0.37    0.63    0.59    0.63    0.60    0.60  \n",
      "  0.025    1.92    0.77    0.51    1.13    0.32    0.81    1.17    1.19    0.75    0.84    0.77    0.76    0.65    0.62    0.72  \n",
      "  0.032    2.64   -0.06    0.73    1.47   -0.61    0.93    0.90    0.90    1.08    0.83    0.69    0.84    0.90    0.78    0.86  \n",
      "  0.040    1.08    0.04    0.99    2.99    1.46    1.41    2.07    0.72    1.65    0.85    0.72    0.91    0.84    0.95    1.04  \n",
      "  0.050    1.80    0.01    0.93    1.95    1.11    1.87    1.51    0.60    1.30    1.01    0.70    0.88    1.15    1.09    1.13  \n",
      "  0.063    1.28    0.96    3.03    0.88   -0.09    1.72    0.72    0.77    1.77    1.38    0.92    0.98    1.00    0.95    1.51  \n",
      "  0.079   -0.50   -0.20    2.63    2.10   -1.61    2.31    0.70    1.05    1.55    1.10    0.76    0.95    1.04    1.05    4.80  \n",
      "  0.100   -0.37    0.00   -0.46    1.28    1.03    1.33    1.34    1.12    1.34    0.58    0.70    0.87    0.95    1.63    7.43  \n",
      "  0.126    1.21    0.28   -1.78   -0.20    0.35    0.87    0.89    0.87    1.11    0.49    0.54    0.81    0.83    5.41    9.14  \n",
      "  0.158    2.42   -0.52   -2.45   -0.35   -0.31    0.39   -0.43    0.43    0.60    0.36    0.55    0.43    0.71    6.19    9.89  \n",
      "  0.200   -0.04   -2.69   -2.69    0.55    0.10   -0.75   -0.38   -0.04    0.36    0.22    0.30    0.34    0.87    7.09   10.46  \n",
      "  0.251   -0.30   -0.72   -2.70   -2.22   -1.25   -0.01    0.64    0.31    0.40   -0.31    0.13    0.41    1.55    8.50   10.80  \n",
      "  0.316    1.92   -1.18   -3.31   -3.32   -1.61   -0.33   -0.28    0.06   -0.02   -0.44    0.04    0.31    3.04    8.94   11.12  \n",
      "  0.398    1.90   -2.07   -2.04   -1.30   -1.19   -1.01    0.03   -0.42    0.37   -0.77   -0.02    0.28    6.08    9.54   11.52  \n",
      "  0.501    0.74   -2.75   -3.49   -1.87   -1.74   -0.91   -0.11    0.11    0.02   -0.76   -0.01   -0.01    7.06   10.71   12.06  \n",
      "  0.631    0.96   -5.10   -6.92   -6.10   -0.24   -1.50   -2.10   -0.74   -0.65   -0.77    0.06    0.44    8.34   11.49   12.60  \n",
      "  0.794    1.68   -3.19   -4.47   -5.45   -1.70   -2.23   -1.73   -0.79   -0.25   -0.61    0.18    1.61    9.49   12.38   13.24  \n",
      "  1.000    0.65   -4.15   -4.28   -3.54   -3.30   -2.23   -1.26   -1.12   -0.23    0.40    0.64    5.98   10.65   12.80   13.98  \n",
      "CPU times: user 851 ms, sys: 8.75 s, total: 9.6 s\n",
      "Wall time: 31min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res_fresh = exp(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27798438-ec96-4db7-b59d-b3655031c2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29f6fafb-1476-49d3-82c0-8d61dcae426c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.88,  0.66,  0.41,  0.45,  0.85,  1.04, -0.04, -0.02,  0.43,  0.43,  0.42,  0.38,  0.41,  0.26,  0.34],\n",
       "       [ 0.6 ,  1.12,  1.19,  0.86,  0.41,  1.27, -0.2 ,  0.1 ,  0.54,  0.66,  0.35,  0.6 ,  0.47,  0.37,  0.43],\n",
       "       [ 0.32, -1.52, -0.68,  1.11,  1.93,  0.96,  0.87,  0.64,  0.36,  0.3 ,  0.69,  0.48,  0.53,  0.5 ,  0.5 ],\n",
       "       [-0.  ,  0.64,  0.66,  0.79,  2.07,  1.34,  0.82,  0.59,  0.1 ,  0.37,  0.63,  0.59,  0.63,  0.6 ,  0.6 ],\n",
       "       [ 1.92,  0.77,  0.51,  1.13,  0.32,  0.81,  1.17,  1.19,  0.75,  0.84,  0.77,  0.76,  0.65,  0.62,  0.72],\n",
       "       [ 2.64, -0.06,  0.73,  1.47, -0.61,  0.93,  0.9 ,  0.9 ,  1.08,  0.83,  0.69,  0.84,  0.9 ,  0.78,  0.86],\n",
       "       [ 1.08,  0.04,  0.99,  2.99,  1.46,  1.41,  2.07,  0.72,  1.65,  0.85,  0.72,  0.91,  0.84,  0.95,  1.04],\n",
       "       [ 1.8 ,  0.01,  0.93,  1.95,  1.11,  1.87,  1.51,  0.6 ,  1.3 ,  1.01,  0.7 ,  0.88,  1.15,  1.09,  1.13],\n",
       "       [ 1.28,  0.96,  3.03,  0.88, -0.09,  1.72,  0.72,  0.77,  1.77,  1.38,  0.92,  0.98,  1.  ,  0.95,  1.51],\n",
       "       [-0.5 , -0.2 ,  2.63,  2.1 , -1.61,  2.31,  0.7 ,  1.05,  1.55,  1.1 ,  0.76,  0.95,  1.04,  1.05,  4.8 ],\n",
       "       [-0.37,  0.  , -0.46,  1.28,  1.03,  1.33,  1.34,  1.12,  1.34,  0.58,  0.7 ,  0.87,  0.95,  1.63,  7.43],\n",
       "       [ 1.21,  0.28, -1.78, -0.2 ,  0.35,  0.87,  0.89,  0.87,  1.11,  0.49,  0.54,  0.81,  0.83,  5.41,  9.14],\n",
       "       [ 2.42, -0.52, -2.45, -0.35, -0.31,  0.39, -0.43,  0.43,  0.6 ,  0.36,  0.55,  0.43,  0.71,  6.19,  9.89],\n",
       "       [-0.04, -2.69, -2.69,  0.55,  0.1 , -0.75, -0.38, -0.04,  0.36,  0.22,  0.3 ,  0.34,  0.87,  7.09, 10.46],\n",
       "       [-0.3 , -0.72, -2.7 , -2.22, -1.25, -0.01,  0.64,  0.31,  0.4 , -0.31,  0.13,  0.41,  1.55,  8.5 , 10.8 ],\n",
       "       [ 1.92, -1.18, -3.31, -3.32, -1.61, -0.33, -0.28,  0.06, -0.02, -0.44,  0.04,  0.31,  3.04,  8.94, 11.12],\n",
       "       [ 1.9 , -2.07, -2.04, -1.3 , -1.19, -1.01,  0.03, -0.42,  0.37, -0.77, -0.02,  0.28,  6.08,  9.54, 11.52],\n",
       "       [ 0.74, -2.75, -3.49, -1.87, -1.74, -0.91, -0.11,  0.11,  0.02, -0.76, -0.01, -0.01,  7.06, 10.71, 12.06],\n",
       "       [ 0.96, -5.1 , -6.92, -6.1 , -0.24, -1.5 , -2.1 , -0.74, -0.65, -0.77,  0.06,  0.44,  8.34, 11.49, 12.6 ],\n",
       "       [ 1.68, -3.19, -4.47, -5.45, -1.7 , -2.23, -1.73, -0.79, -0.25, -0.61,  0.18,  1.61,  9.49, 12.38, 13.24],\n",
       "       [ 0.65, -4.15, -4.28, -3.54, -3.3 , -2.23, -1.26, -1.12, -0.23,  0.4 ,  0.64,  5.98, 10.65, 12.8 , 13.98]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res020.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01f3fc6-fe5f-4b37-bd18-f3845a687da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f76830-a8ee-4938-9550-d4a097c319c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bb41e1b-4e82-4e4f-8740-679bc6fcac99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Student: 0.040\n",
      "\n",
      "         Curriculum Size\n",
      "Teacher       0      32      64     128     256     512    1024    2048    4096    8192   16384   32768   65536\n",
      "  0.010    7.18    7.04    7.05    7.00    6.90    6.98    6.47    5.79    4.76    3.11    2.10    1.65    1.36  \n",
      "  0.013    7.18    7.04    7.05    7.00    6.90    6.98    6.49    5.89    5.19    3.85    2.89    2.44    2.02  \n",
      "  0.016    7.18    7.04    7.05    7.01    6.94    7.07    6.60    6.25    5.55    4.52    3.45    3.14    2.77  \n",
      "  0.020    7.18    7.04    7.06    7.02    6.97    7.14    6.71    6.50    5.90    5.08    4.42    3.97    3.71  \n",
      "  0.025    7.18    7.05    7.06    7.02    7.05    7.12    6.84    6.33    5.44    5.54    5.08    5.10    4.81  \n",
      "  0.032    7.18    7.06    7.07    7.04    7.11    7.20    6.95    6.73    6.01    6.10    5.84    6.01    5.91  \n",
      "  0.040    7.18    7.05    7.07    7.05    7.14    7.29    7.16    7.10    6.66    7.03    6.79    7.11    7.11  \n",
      "  0.050    7.18    7.05    7.07    7.05    7.15    7.36    7.32    7.47    7.46    7.93    7.98    8.35    8.24  \n",
      "  0.063    7.18    7.06    7.08    7.07    7.16    7.40    7.35    8.08    8.83    9.01    9.34    9.65    9.53  \n",
      "  0.079    7.18    7.06    7.08    7.07    7.18    7.48    7.62    8.74    9.62   10.21   10.33   10.75   10.78  \n",
      "  0.100    7.18    7.06    7.09    7.08    7.21    7.58    7.83    9.26   10.65   11.00   11.40   11.76   11.81  \n",
      "  0.126    7.18    7.06    7.09    7.10    7.24    7.64    7.99    9.61   11.27   11.84   12.15   12.33   12.54  \n",
      "  0.158    7.18    7.06    7.09    7.11    7.27    7.70    8.33   10.09   11.58   12.54   12.85   12.95   13.06  \n",
      "  0.200    7.18    7.06    7.10    7.12    7.29    7.75    8.46   10.34   12.02   12.80   13.19   13.25   13.36  \n",
      "  0.251    7.18    7.06    7.10    7.12    7.30    7.77    8.52   10.48   12.11   12.87   13.34   13.47   13.60  \n",
      "  0.316    7.18    7.06    7.09    7.12    7.31    7.79    8.61   10.61   12.25   13.07   13.50   13.63   13.80  \n",
      "  0.398    7.18    7.06    7.08    7.09    7.28    7.77    8.42   10.67   12.61   13.25   13.66   13.83   13.90  \n",
      "  0.501    7.18    7.06    7.10    7.14    7.35    7.86    8.48   11.06   12.95   13.64   13.89   14.02   14.19  \n",
      "  0.631    7.18    7.05    7.10    7.15    7.37    7.90    8.66   11.63   13.40   13.94   14.14   14.31   14.43  \n",
      "  0.794    7.18    7.06    7.10    7.16    7.38    7.98    8.93   12.51   13.75   14.25   14.47   14.64   14.74  \n",
      "  1.000    7.18    7.06    7.10    7.14    7.37    8.10    8.82   13.09   14.34   14.61   14.93   14.99   15.10  \n",
      "CPU times: user 670 ms, sys: 3.62 s, total: 4.29 s\n",
      "Wall time: 11min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res040 = exp(0.040)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ced6103-67d8-4403-8604-842836509611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bca92861-79ac-423e-a0c8-df9c1b23e84f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Student: 0.100\n",
      "\n",
      "         Curriculum Size\n",
      "Teacher       0      32      64     128     256     512    1024    2048    4096    8192   16384   32768   65536\n",
      "  0.010   11.71   11.62   11.52   11.40   10.97    9.13    5.82    2.99    1.70    0.62    0.46    0.39    0.41  \n",
      "  0.013   11.71   11.62   11.52   11.40   10.98    9.21    6.04    3.33    1.80    1.05    0.76    0.60    0.69  \n",
      "  0.016   11.71   11.62   11.52   11.42   11.05    9.35    6.59    4.42    2.50    1.32    1.06    0.99    1.11  \n",
      "  0.020   11.71   11.62   11.53   11.44   11.10    9.64    7.25    5.05    3.91    2.43    2.22    2.04    2.20  \n",
      "  0.025   11.71   11.63   11.55   11.48   11.29   10.47    7.76    4.92    3.59    3.41    3.00    3.36    3.66  \n",
      "  0.032   11.71   11.63   11.55   11.49   11.36   10.71    7.49    5.08    3.90    4.27    4.29    4.78    5.22  \n",
      "  0.040   11.71   11.63   11.56   11.53   11.45   10.96    8.78    6.83    5.56    6.20    5.93    6.31    6.60  \n",
      "  0.050   11.71   11.64   11.57   11.55   11.50   11.15    9.83    8.19    7.28    7.50    7.34    7.75    7.96  \n",
      "  0.063   11.71   11.63   11.57   11.56   11.50   11.04   10.15    9.85    9.57    8.66    9.15    9.31    9.18  \n",
      "  0.079   11.71   11.64   11.58   11.60   11.60   11.35   11.21   11.21   10.59   10.25   10.21   10.54   10.65  \n",
      "  0.100   11.71   11.64   11.60   11.64   11.69   11.62   11.74   11.94   11.87   11.26   11.43   11.67   11.76  \n",
      "  0.126   11.71   11.64   11.60   11.65   11.72   11.74   11.95   12.22   12.40   12.25   12.30   12.37   12.60  \n",
      "  0.158   11.71   11.64   11.60   11.66   11.77   11.92   12.19   12.35   12.67   12.77   12.86   12.89   13.02  \n",
      "  0.200   11.71   11.64   11.60   11.66   11.78   11.92   12.28   12.53   12.84   12.92   13.12   13.21   13.29  \n",
      "  0.251   11.71   11.64   11.60   11.66   11.78   11.94   12.28   12.61   12.84   12.98   13.18   13.40   13.48  \n",
      "  0.316   11.71   11.65   11.60   11.66   11.79   11.94   12.27   12.57   12.91   13.02   13.27   13.58   13.64  \n",
      "  0.398   11.71   11.64   11.60   11.66   11.78   11.97   12.38   12.74   12.99   13.16   13.41   13.75   13.80  \n",
      "  0.501   11.71   11.64   11.60   11.67   11.80   12.01   12.37   12.73   13.04   13.23   13.53   13.90   14.03  \n",
      "  0.631   11.71   11.64   11.60   11.67   11.80   12.00   12.42   12.78   13.10   13.31   13.65   14.12   14.30  \n",
      "  0.794   11.71   11.65   11.60   11.68   11.83   12.02   12.41   12.75   13.12   13.49   13.92   14.38   14.59  \n",
      "  1.000   11.71   11.65   11.60   11.68   11.84   12.10   12.50   12.87   13.16   13.40   13.93   14.50   14.88  \n",
      "CPU times: user 683 ms, sys: 3.65 s, total: 4.33 s\n",
      "Wall time: 11min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res020 = exp(0.100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6d2f9d-d509-4153-accc-7ae446ebfe65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
